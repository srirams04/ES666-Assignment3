{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 71\u001b[0m\n\u001b[0;32m     68\u001b[0m images \u001b[38;5;241m=\u001b[39m [img \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m images \u001b[38;5;28;01mif\u001b[39;00m img \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# Stitch the images into a panorama\u001b[39;00m\n\u001b[1;32m---> 71\u001b[0m stitched_panorama \u001b[38;5;241m=\u001b[39m \u001b[43mstitch_multiple_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# Show and save the result\u001b[39;00m\n\u001b[0;32m     74\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStitched Panorama\u001b[39m\u001b[38;5;124m\"\u001b[39m, stitched_panorama)\n",
      "Cell \u001b[1;32mIn[1], line 50\u001b[0m, in \u001b[0;36mstitch_multiple_images\u001b[1;34m(images)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstitch_multiple_images\u001b[39m(images):\n\u001b[0;32m     49\u001b[0m     reference_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(images) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m---> 50\u001b[0m     panorama \u001b[38;5;241m=\u001b[39m \u001b[43mimages\u001b[49m\u001b[43m[\u001b[49m\u001b[43mreference_idx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(reference_idx \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m     52\u001b[0m         img1_gray \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(images[i], cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def detect_and_match_keypoints(img1_gray, img2_gray):\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints1, descriptors1 = sift.detectAndCompute(img1_gray, None)\n",
    "    keypoints2, descriptors2 = sift.detectAndCompute(img2_gray, None)\n",
    "    index_params = dict(algorithm=1, trees=5)\n",
    "    search_params = dict(checks=50)\n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "    matches = flann.knnMatch(descriptors1, descriptors2, k=2)\n",
    "    good_matches = [m for m, n in matches if m.distance < 0.75 * n.distance]\n",
    "    points1 = np.float32([keypoints1[m.queryIdx].pt for m in good_matches])\n",
    "    points2 = np.float32([keypoints2[m.trainIdx].pt for m in good_matches])\n",
    "    return points1, points2\n",
    "\n",
    "def compute_homography(points1, points2):\n",
    "    H, _ = cv2.findHomography(points1, points2, cv2.RANSAC)\n",
    "    return H\n",
    "\n",
    "def warp_image_with_blending(img1, img2, H):\n",
    "    h1, w1 = img1.shape[:2]\n",
    "    h2, w2 = img2.shape[:2]\n",
    "    corners_img1 = np.float32([[0, 0], [0, h1], [w1, h1], [w1, 0]]).reshape(-1, 1, 2)\n",
    "    warped_corners = cv2.perspectiveTransform(corners_img1, H)\n",
    "    corners_img2 = np.float32([[0, 0], [0, h2], [w2, h2], [w2, 0]]).reshape(-1, 1, 2)\n",
    "    all_corners = np.concatenate((warped_corners, corners_img2), axis=0)\n",
    "    [x_min, y_min] = np.int32(all_corners.min(axis=0).ravel() - 0.5)\n",
    "    [x_max, y_max] = np.int32(all_corners.max(axis=0).ravel() + 0.5)\n",
    "    translation_dist = [-x_min, -y_min]\n",
    "    translation_matrix = np.array([[1, 0, translation_dist[0]], [0, 1, translation_dist[1]], [0, 0, 1]])\n",
    "    output_img = cv2.warpPerspective(img1, translation_matrix @ H, (x_max - x_min, y_max - y_min))\n",
    "    output_img[translation_dist[1]:h2 + translation_dist[1], translation_dist[0]:w2 + translation_dist[0]] = img2\n",
    "\n",
    "    mask1 = np.zeros((h2, w2), dtype=np.uint8)\n",
    "    mask1[:, :] = 255\n",
    "    mask1_warped = cv2.warpPerspective(mask1, translation_matrix @ H, (x_max - x_min, y_max - y_min))\n",
    "\n",
    "    dist_transform_img1 = cv2.distanceTransform(mask1_warped, cv2.DIST_L2, 5)\n",
    "    dist_transform_img2 = cv2.distanceTransform(255 - mask1_warped, cv2.DIST_L2, 5)\n",
    "    blend_mask1 = dist_transform_img1 / (dist_transform_img1 + dist_transform_img2 + 1e-10)\n",
    "    blend_mask2 = dist_transform_img2 / (dist_transform_img1 + dist_transform_img2 + 1e-10)\n",
    "    blended_output = np.zeros_like(output_img)\n",
    "    for c in range(3):\n",
    "        blended_output[:, :, c] = (output_img[:, :, c] * blend_mask1 + img2[:, :, c] * blend_mask2).astype(np.uint8)\n",
    "    return blended_output\n",
    "\n",
    "def stitch_multiple_images(images):\n",
    "    reference_idx = len(images) // 2\n",
    "    panorama = images[reference_idx]\n",
    "    for i in range(reference_idx - 1, -1, -1):\n",
    "        img1_gray = cv2.cvtColor(images[i], cv2.COLOR_BGR2GRAY)\n",
    "        img2_gray = cv2.cvtColor(panorama, cv2.COLOR_BGR2GRAY)\n",
    "        points1, points2 = detect_and_match_keypoints(img1_gray, img2_gray)\n",
    "        H = compute_homography(points1, points2)\n",
    "        panorama = warp_image_with_blending(images[i], panorama, H)\n",
    "    \n",
    "    for i in range(reference_idx + 1, len(images)):\n",
    "        img1_gray = cv2.cvtColor(images[i], cv2.COLOR_BGR2GRAY)\n",
    "        img2_gray = cv2.cvtColor(panorama, cv2.COLOR_BGR2GRAY)\n",
    "        points1, points2 = detect_and_match_keypoints(img1_gray, img2_gray)\n",
    "        H = compute_homography(points1, points2)\n",
    "        panorama = warp_image_with_blending(images[i], panorama, H)\n",
    "    return panorama\n",
    "\n",
    "# Load images in color\n",
    "image_files = ['STA_0031.jpg', 'STB_0032.jpg', 'STC_0033.jpg', 'STD_0034.jpg', 'STE_0035.jpg', 'STF_0036.jpg']\n",
    "images = [cv2.imread(f) for f in image_files]\n",
    "images = [img for img in images if img is not None]\n",
    "\n",
    "# Stitch the images into a panorama\n",
    "stitched_panorama = stitch_multiple_images(images)\n",
    "\n",
    "# Show and save the result\n",
    "cv2.imshow(\"Stitched Panorama\", stitched_panorama)\n",
    "cv2.imwrite(\"stitched_panorama.jpg\", stitched_panorama)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
